{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "efe99fc9f6a1fa26d7fb8d05974514278fd0ec0a"
   },
   "source": [
    "### This is the first part of @afajohn kernel with the addition of multiprocessing on the test set\n",
    "Check out his brilliant kernel here https://www.kaggle.com/afajohn/cnn-lstm-for-signal-classification-lb-0-513\n",
    "\n",
    "Also, many thanks to following kernels:\n",
    "- For shortening the signals with a simple feature extraction thanks to: https://www.kaggle.com/ashishpatel26/transfer-learning-in-basic-nn\n",
    "- For signal denoising and fft: https://www.kaggle.com/theoviel/fast-fourier-transform-denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import gc\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "from multiprocessing import Pool, current_process\n",
    "from multiprocessing import log_to_stderr, get_logger\n",
    "from tqdm import tqdm\n",
    "from numba import jit\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import LSTM,Dropout,Dense,TimeDistributed,Conv1D,MaxPooling1D,Flatten\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "e06765b00810004c271944be1360e0b62fa64134"
   },
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "935c2ba4d25cae753e04645a168decb84b6ce964"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.5 s, sys: 25.6 s, total: 1min 22s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "train_set = pq.read_pandas('../input/train.parquet').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "e217109aeec443c5cb64fdc716ef433f306c436c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25 ms, sys: 5.52 ms, total: 30.5 ms\n",
      "Wall time: 46.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "meta_train = pd.read_csv('../input/metadata_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "36f9662e947b286fa6505a4c8183daff1b8c1570"
   },
   "outputs": [],
   "source": [
    "@jit('float32(float32[:,:], int32)')\n",
    "def feature_extractor(x, n_part=1000):\n",
    "    lenght = len(x)\n",
    "    pool = np.int32(np.ceil(lenght/n_part))\n",
    "    output = np.zeros((n_part,))\n",
    "    for j, i in enumerate(range(0,lenght, pool)):\n",
    "        if i+pool < lenght:\n",
    "            k = x[i:i+pool]\n",
    "        else:\n",
    "            k = x[i:]\n",
    "        output[j] = np.max(k, axis=0) - np.min(k, axis=0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "83ce36dd1a85aaad8b446e452cbc7e19b882164b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8712/8712 [01:43<00:00, 84.39it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "for i in tqdm(meta_train.signal_id):\n",
    "    idx = meta_train.loc[meta_train.signal_id==i, 'signal_id'].values.tolist()\n",
    "    y_train.append(meta_train.loc[meta_train.signal_id==i, 'target'].values)\n",
    "    x_train.append(abs(feature_extractor(train_set.iloc[:, idx].values, n_part=400)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "4cc6eef2ae63a2c79d08c5fe1ce8670449fb807a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31671"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_set; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "cad66118494f25f70c9ace7b85bea500f1c680c8"
   },
   "outputs": [],
   "source": [
    "y_train = np.array(y_train).reshape(-1,)\n",
    "X_train = np.array(x_train).reshape(-1,x_train[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "5250bf32e062836cbf10394e5f9df4d6b695380e"
   },
   "outputs": [],
   "source": [
    "def keras_auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "034ea6d8cf8bd8a09eb5943ebb3faa01cd991e9d"
   },
   "outputs": [],
   "source": [
    "n_signals = 1 #So far each instance is one signal. We will diversify them in next step\n",
    "n_outputs = 1 #Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "1c05ecc6abef0b822e422950a5824ea8c55ba861"
   },
   "outputs": [],
   "source": [
    "#Build the model\n",
    "verbose, epochs, batch_size = True, 15, 16\n",
    "n_steps, n_length = 40, 10\n",
    "X_train = X_train.reshape((X_train.shape[0], n_steps, n_length, n_signals))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=(None,n_length,n_signals)))\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "model.add(TimeDistributed(Dropout(0.5)))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "e48f5b3c1e9cffb34ef0f395f668a205b9cd2508"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[keras_auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "7092f9b2feb4b98b47a72738b956a38f178e0075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "8712/8712 [==============================] - 29s 3ms/step - loss: 0.2217 - keras_auc: 0.5647\n",
      "Epoch 2/15\n",
      "8712/8712 [==============================] - 27s 3ms/step - loss: 0.1710 - keras_auc: 0.7079\n",
      "Epoch 3/15\n",
      "8712/8712 [==============================] - 27s 3ms/step - loss: 0.1410 - keras_auc: 0.8020\n",
      "Epoch 4/15\n",
      "8712/8712 [==============================] - 27s 3ms/step - loss: 0.1376 - keras_auc: 0.8464\n",
      "Epoch 5/15\n",
      "8712/8712 [==============================] - 28s 3ms/step - loss: 0.1249 - keras_auc: 0.8698\n",
      "Epoch 6/15\n",
      "8712/8712 [==============================] - 27s 3ms/step - loss: 0.1256 - keras_auc: 0.8840\n",
      "Epoch 7/15\n",
      "8712/8712 [==============================] - 28s 3ms/step - loss: 0.1245 - keras_auc: 0.8940\n",
      "Epoch 8/15\n",
      "8712/8712 [==============================] - 27s 3ms/step - loss: 0.1149 - keras_auc: 0.9018\n",
      "Epoch 9/15\n",
      "8712/8712 [==============================] - 27s 3ms/step - loss: 0.1153 - keras_auc: 0.9082\n",
      "Epoch 10/15\n",
      "8712/8712 [==============================] - 29s 3ms/step - loss: 0.1119 - keras_auc: 0.9126\n",
      "Epoch 11/15\n",
      "8712/8712 [==============================] - 27s 3ms/step - loss: 0.1096 - keras_auc: 0.9172\n",
      "Epoch 12/15\n",
      "8712/8712 [==============================] - 28s 3ms/step - loss: 0.1109 - keras_auc: 0.9207\n",
      "Epoch 13/15\n",
      "6160/8712 [====================>.........] - ETA: 8s - loss: 0.1069 - keras_auc: 0.9232"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "470dee0dc3d9edaaad403eb14275308cb84fb9f8"
   },
   "outputs": [],
   "source": [
    "model.save_weights('model1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "b515018688a91e01db25789607fba7e2be3b2216"
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "meta_test = pd.read_csv('../input/metadata_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "ea6ad7ea1e2489484c451c1fed4e0bd5f9f770a3"
   },
   "outputs": [],
   "source": [
    "def process_chunk(arg):\n",
    "    start_index = arg['start_index']\n",
    "    chunk_size = arg['chunk_size']\n",
    "    \n",
    "    # Test set indices start at 8712\n",
    "    test_set_start = 8712\n",
    "    offset_index = (test_set_start + start_index)\n",
    "    \n",
    "    # Column name must be a string\n",
    "    subset_test = pq.read_pandas('../input/test.parquet', columns=[str(offset_index + j) for j in range(chunk_size)]).to_pandas()    \n",
    "    x_test = []\n",
    "    for j in range(chunk_size):\n",
    "        subset_test_row = subset_test[str(offset_index + j)]\n",
    "        x_test.append(abs(feature_extractor(subset_test_row.values, n_part=400)))\n",
    "    return x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "28cf5f6f80b5032b735384c4ddaf8b6b55dc046c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_cpu:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in byte_scalars\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in byte_scalars\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in byte_scalars\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in byte_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi processing complete. len: 21\n"
     ]
    }
   ],
   "source": [
    "# Define 21 chunks for processing the test set\n",
    "# on multiple cpus. I have choosen to process in chunks of 1000 (plus the remainder)\n",
    "# so as to keep within the kernels memory limit\n",
    "args = []\n",
    "for i in range(0, 20000, 1000):\n",
    "    args.append({\n",
    "        'start_index': i,\n",
    "        'chunk_size': 1000\n",
    "    })\n",
    "    \n",
    "# Add a chunk for the remainder\n",
    "args.append({\n",
    "    'start_index': 20000,\n",
    "    'chunk_size': 337\n",
    "})\n",
    "\n",
    "n_cpu = processes=os.cpu_count()\n",
    "print('n_cpu: ', n_cpu)\n",
    "\n",
    "p = Pool(processes=n_cpu)\n",
    "\n",
    "# Map the chunk args to the the process_chunk function\n",
    "x_test_chunks = p.map(process_chunk, args)\n",
    "print(f\"multi processing complete. len: {len(x_test_chunks)}\")\n",
    "\n",
    "p.close()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "e367d00a29dabeb7e85d8239d5d252f112e6c819"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test.shape:  (20337, 400)\n"
     ]
    }
   ],
   "source": [
    "x_test = [item for sublist in x_test_chunks for item in sublist]\n",
    "x_test = np.array(x_test)\n",
    "print('x_test.shape: ', x_test.shape)\n",
    "X_test = x_test.reshape((x_test.shape[0], n_steps, n_length, n_signals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "fe048f7596bb0309df92293e183586425794213c"
   },
   "outputs": [],
   "source": [
    "del x_test_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "a849fe7c203cb3bf1e31bca15c85ea1e12d6a3fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20337, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "96ad54116ff05d45fee610b69fcabe96b16db00b"
   },
   "outputs": [],
   "source": [
    "threshpreds = (preds>0.5)*1\n",
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "sub.target = threshpreds\n",
    "\n",
    "# Gave me an LB score of ~0.450\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "b76b5959e2127dc660d8fd0d9bae548621580241"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8717</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8718</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8721</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8722</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8723</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8726</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8729</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    signal_id  target\n",
       "0        8712       0\n",
       "1        8713       0\n",
       "2        8714       0\n",
       "3        8715       0\n",
       "4        8716       0\n",
       "5        8717       0\n",
       "6        8718       0\n",
       "7        8719       0\n",
       "8        8720       0\n",
       "9        8721       0\n",
       "10       8722       0\n",
       "11       8723       0\n",
       "12       8724       0\n",
       "13       8725       0\n",
       "14       8726       0\n",
       "15       8727       0\n",
       "16       8728       0\n",
       "17       8729       0\n",
       "18       8730       0\n",
       "19       8731       0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_sub = pd.read_csv('submission.csv')\n",
    "check_sub.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "d9e155e960b61d529796df6f384ff968412ea622"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 230682,
     "sourceId": 10684,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 19667,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
